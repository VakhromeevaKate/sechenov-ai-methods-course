{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6h/Z5knBhXMI71vKF2cUf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VakhromeevaKate/sechenov-ai-methods-course/blob/main/Scipy_Keras_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4J66eM0ncEpg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scikit-learn, TensorFlow, Keras и PyTorch для Машинного Обучения\n",
        "\n"
      ],
      "metadata": {
        "id": "wOfdFNEocFcu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.Scikit-learn — для классического ML\n",
        "\n",
        "### Зачем он используется?\n",
        "\n",
        "Scikit-learn — это библиотека для классического машинного обучения. Она идеальна для работы с структурированными данными (таблицами). Ее основные задачи:\n",
        "\n",
        "- Обучение с учителем (классификация, регрессия)\n",
        "\n",
        "- Обучение без учителя (кластеризация, снижение размерности)\n",
        "\n",
        "- Предобработка данных, выбор моделей, оценка качества.\n",
        "\n",
        "Ключевые принципы:\n",
        "\n",
        "Единый API: У всех моделей есть методы .fit(), .predict(), .score().\n",
        "\n",
        "Конвейеры (Pipelines): Позволяют объединить этапы предобработки и моделирования в одну цепочку.\n",
        "\n",
        "Основные методы и модули:\n",
        "\n",
        "- sklearn.model_selection.train_test_split — разделение данных на обучающую и тестовую выборки.\n",
        "\n",
        "- sklearn.preprocessing (StandardScaler, LabelEncoder) — предобработка данных.\n",
        "\n",
        "- sklearn.linear_model (LogisticRegression, LinearRegression) — линейные модели.\n",
        "\n",
        "- sklearn.ensemble (RandomForestClassifier, GradientBoostingRegressor) — ансамбли (одни из лучших \"готовых\" моделей).\n",
        "\n",
        "- sklearn.metrics (accuracy_score, classification_report) — метрики для оценки качества.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4GQ8fO6FceQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример: классификация ирисов Фишера\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Загрузка данных\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Разделение на тренировочную и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Создание и обучение модели\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Предсказание и оценка\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Точность модели: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JT97wNVlc3xi",
        "outputId": "ea011842-c982-48e2-ce88-509f2fcead4c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Точность модели: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TensorFlow — вычислительный движок для численных задач\n",
        "\n",
        "### Зачем он используется?\n",
        "TensorFlow (TF) — это низкоуровневая библиотека для численных вычислений с акцентом на глубокое обучение. Ее главная сила:\n",
        "\n",
        "- Создание и обучение нейронных сетей любой сложности.\n",
        "- Работа на CPU, GPU и TPU для ускорения вычислений.\n",
        "\n",
        "Использование вычислительных графов (хотя в TF 2.x это скрыто за простым API).\n",
        "\n",
        "Ключевые концепции:\n",
        "- Тензоры (Tensors): Многомерные массивы — основная единица данных в TF.\n",
        "- Графы (Graphs): Раньше нужно было явно строить граф операций. Сейчас это делается автоматически в режиме Eager Execution (\"жадное выполнение\"), что делает код интуитивно понятным."
      ],
      "metadata": {
        "id": "AIHWZhaxdBnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример: Умножение тензоров\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Создание тензоров\n",
        "a = tf.constant([[1, 2], [3, 4]])\n",
        "b = tf.constant([[5, 6], [7, 8]])\n",
        "\n",
        "# Матричное умножение (основа многих операций в НС)\n",
        "c = tf.matmul(a, b)\n",
        "\n",
        "print(\"Результат умножения матриц:\")\n",
        "print(c.numpy()) # .numpy() преобразует тензор TF в массив NumPy\n",
        "\n",
        "# Вывод:\n",
        "# [[19 22]\n",
        "#  [43 50]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SlpWUgDdS9R",
        "outputId": "1813b2d8-f93a-4428-fb54-927f13e1071d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат умножения матриц:\n",
            "[[19 22]\n",
            " [43 50]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keras — высокоуровневый API для глубокого обучения\n",
        "\n",
        "### Зачем он используется?\n",
        "Keras — это высокоуровневый API, который теперь является стандартной частью TensorFlow (tf.keras). Он создан для быстрого прототипирования нейронных сетей. Его девиз: \"Быстрые эксперименты с глубоким обучением\".\n",
        "\n",
        "Почему он популярен:\n",
        "- Простота и удобство чтения: Позволяет описывать сложные сети в несколько строк кода.\n",
        "- Модульность: Модель собирается как конструктор из \"блоков\" (слоев).\n",
        "- Работает поверх бэкендов: Изначально работал с TF, Theano, CNTK, сейчас — часть TF.\n",
        "\n",
        "Ключевые методы и концепции:\n",
        "- Sequential API: Простейший способ построения модели \"слой за слоем\".\n",
        "- Функциональный API: Для построения более сложных моделей (например, с несколькими входами/выходами).\n",
        "- Слои (Layers): Dense (полносвязный), Conv2D (сверточный), LSTM (рекуррентный).\n",
        "- Компиляция модели: model.compile() — здесь задаются оптимизатор, функция потерь и метрики.\n",
        "- Обучение: model.fit() — основной метод для обучения."
      ],
      "metadata": {
        "id": "DV5V69h2dhbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Нейронная сеть для классификации одежды (Fashion-MNIST)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# 1. Загрузка и подготовка данных\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Нормализация данных (приводим значения пикселей к диапазону [0, 1])\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n",
        "# 2. Построение модели с помощью Sequential API\n",
        "model = models.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)), # Преобразует изображение 28x28 в вектор из 784 элементов\n",
        "    layers.Dense(128, activation='relu'), # Полносвязный слой со 128 нейронами и функцией активации ReLU\n",
        "    layers.Dropout(0.2),                  # Слой Dropout для борьбы с переобучением\n",
        "    layers.Dense(10, activation='softmax') # Выходной слой с 10 нейронами (по числу классов) и softmax\n",
        "])\n",
        "\n",
        "# 3. Компиляция модели\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 4. Обучение модели\n",
        "history = model.fit(X_train, y_train, epochs=5, validation_split=0.2)\n",
        "\n",
        "# 5. Оценка на тестовых данных\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(f\"\\nТочность на тестовой выборке: {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzZbJCt3d6yL",
        "outputId": "3d30a4cf-7704-494c-c4d2-f4c4a6834084"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.7486 - loss: 0.7084 - val_accuracy: 0.8537 - val_loss: 0.4063\n",
            "Epoch 2/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8494 - loss: 0.4199 - val_accuracy: 0.8574 - val_loss: 0.3843\n",
            "Epoch 3/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8652 - loss: 0.3717 - val_accuracy: 0.8672 - val_loss: 0.3685\n",
            "Epoch 4/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8684 - loss: 0.3559 - val_accuracy: 0.8682 - val_loss: 0.3574\n",
            "Epoch 5/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8777 - loss: 0.3314 - val_accuracy: 0.8783 - val_loss: 0.3375\n",
            "313/313 - 1s - 3ms/step - accuracy: 0.8674 - loss: 0.3722\n",
            "\n",
            "Точность на тестовой выборке: 0.8673999905586243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch — гибкий фреймворк для исследований\n",
        "\n",
        "### Зачем он используется?\n",
        "PyTorch — это фреймворк для глубокого обучения, который сочетает в себе высокую производительность и гибкость. Изначально создавался для научных исследований.\n",
        "\n",
        "Его главные преимущества:\n",
        "- Императивный стиль (Imperative): Код выполняется построчно, как обычный Python (\"define-by-run\").\n",
        "- Динамические графы вычислений: Граф строится на лету во время выполнения операций, что обеспечивает невероятную гибкость.\n",
        "- Тесная интеграция с Python: Ощущается как продолжение Python, а не как отдельный язык.\n",
        "- Отличная поддержка GPU и обширное сообщество.\n",
        "\n",
        "Ключевые концепции:\n",
        "- Тензоры (Tensors): Аналогично TF, но с более \"питоновским\" API.\n",
        "- Autograd: Автоматическое дифференцирование — PyTorch сам вычисляет градиенты.\n",
        "- Модули (torch.nn.Module): Базовый класс для создания моделей.\n",
        "- Оптимизаторы (torch.optim): Алгоритмы оптимизации для обучения."
      ],
      "metadata": {
        "id": "hUgdB0fid_yn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример: Та же нейронная сеть для Fashion-MNIST на PyTorch\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Определение архитектуры модели\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "# 2. Загрузка и подготовка данных\n",
        "def load_data():\n",
        "    # Преобразования для данных\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),  # Конвертируем в тензор и нормализуем к [0, 1]\n",
        "        transforms.Normalize((0.5,), (0.5,))  # Нормализуем к [-1, 1]\n",
        "    ])\n",
        "\n",
        "    # Загрузка датасета Fashion-MNIST\n",
        "    train_dataset = torchvision.datasets.FashionMNIST(\n",
        "        root='./data',\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    test_dataset = torchvision.datasets.FashionMNIST(\n",
        "        root='./data',\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    # Разделение тренировочных данных на обучение и валидацию\n",
        "    train_size = int(0.8 * len(train_dataset))\n",
        "    val_size = len(train_dataset) - train_size\n",
        "    train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "    # Создание DataLoader'ов для батчевой обработки\n",
        "    train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
        "    val_loader = DataLoader(val_subset, batch_size=64, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "# 3. Функция для одного шага обучения\n",
        "def train_epoch(model, train_loader, loss_fn, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch, (X, y) in enumerate(train_loader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Прямой проход\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Обратный проход\n",
        "        optimizer.zero_grad()  # Обнуляем градиенты\n",
        "        loss.backward()        # Вычисляем градиенты\n",
        "        optimizer.step()       # Обновляем веса\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(pred.data, 1)\n",
        "        total += y.size(0)\n",
        "        correct += (predicted == y).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "# 4. Функция для валидации\n",
        "def validate(model, val_loader, loss_fn, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # Отключаем вычисление градиентов для валидации\n",
        "        for X, y in val_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            loss = loss_fn(pred, y)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(pred.data, 1)\n",
        "            total += y.size(0)\n",
        "            correct += (predicted == y).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    avg_loss = total_loss / len(val_loader)\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "# 5. Основной процесс обучения\n",
        "def main():\n",
        "    # Проверяем доступность GPU\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Используется устройство: {device}\")\n",
        "\n",
        "    # Загрузка данных\n",
        "    train_loader, val_loader, test_loader = load_data()\n",
        "\n",
        "    # Инициализация модели\n",
        "    model = NeuralNetwork().to(device)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    print(\"Начало обучения...\")\n",
        "\n",
        "    # Цикл обучения\n",
        "    for epoch in range(5):\n",
        "        # Обучение на одной эпохе\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, loss_fn, optimizer, device)\n",
        "\n",
        "        # Валидация\n",
        "        val_loss, val_acc = validate(model, val_loader, loss_fn, device)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/5:\")\n",
        "        print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "        print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    # 6. Тестирование на тестовой выборке\n",
        "    test_loss, test_acc = validate(model, test_loader, loss_fn, device)\n",
        "    print(f\"\\nРезультат на тестовой выборке:\")\n",
        "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%\")\n",
        "\n",
        "# Запуск основной программы\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8xOR1GGeCW8",
        "outputId": "5eef72f7-5eb6-49f2-b132-8d8925c4a7b7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Используется устройство: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 17.0MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 271kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 5.00MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 6.87MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Начало обучения...\n",
            "Epoch 1/5:\n",
            "  Train Loss: 0.5553, Train Acc: 79.90%\n",
            "  Val Loss: 0.4153, Val Acc: 84.47%\n",
            "--------------------------------------------------\n",
            "Epoch 2/5:\n",
            "  Train Loss: 0.4220, Train Acc: 84.68%\n",
            "  Val Loss: 0.3913, Val Acc: 85.46%\n",
            "--------------------------------------------------\n",
            "Epoch 3/5:\n",
            "  Train Loss: 0.3881, Train Acc: 85.82%\n",
            "  Val Loss: 0.3671, Val Acc: 86.32%\n",
            "--------------------------------------------------\n",
            "Epoch 4/5:\n",
            "  Train Loss: 0.3660, Train Acc: 86.66%\n",
            "  Val Loss: 0.3471, Val Acc: 87.07%\n",
            "--------------------------------------------------\n",
            "Epoch 5/5:\n",
            "  Train Loss: 0.3466, Train Acc: 87.30%\n",
            "  Val Loss: 0.3363, Val Acc: 87.74%\n",
            "--------------------------------------------------\n",
            "\n",
            "Результат на тестовой выборке:\n",
            "Test Loss: 0.3682, Test Accuracy: 86.73%\n"
          ]
        }
      ]
    }
  ]
}